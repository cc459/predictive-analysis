{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6d0e750e-dd96-41f7-847a-cf66908c88cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5f1a3bda-1608-4684-8e29-433be8453bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date',\n",
       " 'Open',\n",
       " 'High',\n",
       " 'Low',\n",
       " 'Close',\n",
       " 'Adj Close',\n",
       " 'Volume',\n",
       " 'neutral-count-finbert',\n",
       " 'positive-count-finbert',\n",
       " 'negative-count-finbert',\n",
       " 'average-confidence-finbert',\n",
       " 'average-neutral-score-gemini',\n",
       " 'average-positive-score-gemini',\n",
       " 'average-negative-score-gemini',\n",
       " 'prediction-label',\n",
       " 'ticker',\n",
       " 'number-employees',\n",
       " 'date_object']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('stock_data.csv')\n",
    "list(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8a0d08bd-9d74-468b-8da1-6c9f4b23f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('stock_data.csv').dropna()\n",
    "\n",
    "df = df.loc[df['ticker'] == 'META']\n",
    "# We assume columns 'open', 'close', 'sentiment_score' for features and 'label' for target\n",
    "df = df[[\n",
    " 'Open',\n",
    " 'High',\n",
    " 'Low',\n",
    " 'Close',\n",
    " 'Adj Close',\n",
    " 'Volume',\n",
    " 'neutral-count-finbert',\n",
    " 'positive-count-finbert',\n",
    " 'negative-count-finbert',\n",
    " 'average-confidence-finbert',\n",
    " 'average-neutral-score-gemini',\n",
    " 'average-positive-score-gemini',\n",
    " 'average-negative-score-gemini',\n",
    " 'prediction-label',\n",
    " ]]\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Scale the features\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(df[[\n",
    " 'Open',\n",
    " 'High',\n",
    " 'Low',\n",
    " 'Close',\n",
    " 'Adj Close',\n",
    " 'Volume',\n",
    " 'neutral-count-finbert',\n",
    " 'positive-count-finbert',\n",
    " 'negative-count-finbert',\n",
    " 'average-confidence-finbert',\n",
    " 'average-neutral-score-gemini',\n",
    " 'average-positive-score-gemini',\n",
    " 'average-negative-score-gemini',\n",
    " ]])\n",
    "\n",
    "# Create a new DataFrame with scaled features\n",
    "df_scaled = pd.DataFrame(scaled_features, columns=[\n",
    " 'Open',\n",
    " 'High',\n",
    " 'Low',\n",
    " 'Close',\n",
    " 'Adj Close',\n",
    " 'Volume',\n",
    " 'neutral-count-finbert',\n",
    " 'positive-count-finbert',\n",
    " 'negative-count-finbert',\n",
    " 'average-confidence-finbert',\n",
    " 'average-neutral-score-gemini',\n",
    " 'average-positive-score-gemini',\n",
    " 'average-negative-score-gemini',\n",
    " ])\n",
    "\n",
    "# Add the target label back to the DataFrame\n",
    "df_scaled['prediction-label'] = df['prediction-label']\n",
    "\n",
    "# Create sequences for LSTM input\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data.iloc[i:i+seq_length, :-1].values)  # All features, excluding the label column\n",
    "        y.append(data.iloc[i+seq_length, -1])  # The label at the next timestep\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Set sequence length (e.g., 10 days of data for each prediction)\n",
    "SEQ_LENGTH = 3\n",
    "\n",
    "# Create sequences\n",
    "X, y = create_sequences(df_scaled, SEQ_LENGTH)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1)  # Ensure y is of shape [batch_size, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "00d3fa3e-a3ca-43d9-9eff-328c6302c62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>neutral-count-finbert</th>\n",
       "      <th>positive-count-finbert</th>\n",
       "      <th>negative-count-finbert</th>\n",
       "      <th>average-confidence-finbert</th>\n",
       "      <th>average-neutral-score-gemini</th>\n",
       "      <th>average-positive-score-gemini</th>\n",
       "      <th>average-negative-score-gemini</th>\n",
       "      <th>prediction-label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.652910</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.652910</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.673569</td>\n",
       "      <td>0.330159</td>\n",
       "      <td>0.303299</td>\n",
       "      <td>0.49343</td>\n",
       "      <td>0.49343</td>\n",
       "      <td>0.122893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.634010</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.727743</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.643848</td>\n",
       "      <td>0.62890</td>\n",
       "      <td>0.62890</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.383713</td>\n",
       "      <td>0.258202</td>\n",
       "      <td>0.188040</td>\n",
       "      <td>0.23317</td>\n",
       "      <td>0.23317</td>\n",
       "      <td>0.121626</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.844531</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.202046</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.843527</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open      High       Low    Close  Adj Close    Volume  \\\n",
       "0  1.000000  0.652910  1.000000  1.00000    1.00000  0.000000   \n",
       "1  1.000000  0.652910  1.000000  1.00000    1.00000  0.000000   \n",
       "2  0.673569  0.330159  0.303299  0.49343    0.49343  0.122893   \n",
       "3  0.727743  1.000000  0.643848  0.62890    0.62890  1.000000   \n",
       "4  0.383713  0.258202  0.188040  0.23317    0.23317  0.121626   \n",
       "5  0.000000  0.000000  0.000000  0.00000    0.00000  0.202046   \n",
       "\n",
       "   neutral-count-finbert  positive-count-finbert  negative-count-finbert  \\\n",
       "0                    0.5                     1.0                     0.0   \n",
       "1                    0.0                     0.0                     1.0   \n",
       "2                    1.0                     0.0                     0.0   \n",
       "3                    0.5                     0.0                     0.5   \n",
       "4                    0.5                     0.0                     0.5   \n",
       "5                    0.5                     0.0                     0.5   \n",
       "\n",
       "   average-confidence-finbert  average-neutral-score-gemini  \\\n",
       "0                    0.000000                      0.333333   \n",
       "1                    0.829423                      0.000000   \n",
       "2                    0.634010                      0.166667   \n",
       "3                    1.000000                      0.500000   \n",
       "4                    0.844531                      0.833333   \n",
       "5                    0.843527                      1.000000   \n",
       "\n",
       "   average-positive-score-gemini  average-negative-score-gemini  \\\n",
       "0                            0.4                         1.0000   \n",
       "1                            0.0                         0.2500   \n",
       "2                            0.5                         0.7500   \n",
       "3                            0.6                         0.0000   \n",
       "4                            0.5                         0.8125   \n",
       "5                            1.0                         0.7500   \n",
       "\n",
       "   prediction-label  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  \n",
       "5               1.0  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fa773400-3ae0-4a76-aa7d-db9186357e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4fafe5a0-f305-4901-92a4-faa9f9867336",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # Define a fully connected (linear) layer for output\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        # Sigmoid activation function because this is a binary classification problem\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # LSTM outputs\n",
    "        lstm_out, (hn, cn) = self.lstm(x)  # hn is the hidden state from the last LSTM layer\n",
    "        \n",
    "        # We take the output from the last time step\n",
    "        out = self.fc(hn[-1])  # hn[-1] is the last hidden state (representing the entire sequence)\n",
    "        out = self.sigmoid(out)  # Apply sigmoid to get a probability\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "81f27503-4fc7-4f8a-83cb-af97a1a36700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = 13  # Number of features in each time step (open, close, sentiment_score)\n",
    "hidden_size = 50  # Number of LSTM units in each layer\n",
    "output_size = 1  # Output size (1 for binary classification)\n",
    "num_layers = 1  # Number of LSTM layers\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Instantiate the model\n",
    "model = LSTMModel(input_size, hidden_size, output_size, num_layers)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Using binary cross entropy loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b00f3561-7a0d-4bcb-ac43-2a64c4b43af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.6532\n",
      "Epoch [20/100], Loss: 0.5147\n",
      "Epoch [30/100], Loss: 0.3380\n",
      "Epoch [40/100], Loss: 0.1608\n",
      "Epoch [50/100], Loss: 0.0607\n",
      "Epoch [60/100], Loss: 0.0258\n",
      "Epoch [70/100], Loss: 0.0143\n",
      "Epoch [80/100], Loss: 0.0097\n",
      "Epoch [90/100], Loss: 0.0075\n",
      "Epoch [100/100], Loss: 0.0061\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # Loop over batches of data using train_loader\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        # Ensure that the inputs are of the correct shape [batch_size, seq_length, input_size]\n",
    "        inputs = inputs.float()  # Ensure input is of type float\n",
    "        targets = targets.float().view(-1, 1)  # Ensure target shape is [batch_size, 1]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)  # Get model predictions for the current batch\n",
    "        loss = criterion(outputs, targets)  # Calculate the loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "        loss.backward()  # Compute gradients\n",
    "        optimizer.step()  # Update model parameters\n",
    "        \n",
    "    # Print loss every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d3d29b5f-cfbb-4cf4-a3e8-b5a3409807a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# After training, evaluate the model\n",
    "model.eval()  # Set model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation during evaluation\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs.float()\n",
    "        targets = targets.float().view(-1, 1)\n",
    "        \n",
    "        outputs = model(inputs)  # Get predictions\n",
    "        predicted_class = (outputs >= 0.5).float()  # Classify as 1 if probability >= 0.5, else 0\n",
    "        \n",
    "        total += targets.size(0)\n",
    "        correct += (predicted_class == targets).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy on test data: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f26b78-b2d4-4ec0-9738-7ad2fdd1c0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f37e98-ff98-4a9a-93cb-a1f28d8906e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
