{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fcb6a01-2b55-49a7-8fc5-0e111b8cea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "922bf23f-604c-4034-b61d-ddf78f805620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>neutral-count-finbert</th>\n",
       "      <th>positive-count-finbert</th>\n",
       "      <th>negative-count-finbert</th>\n",
       "      <th>average-confidence-finbert</th>\n",
       "      <th>average-neutral-score-gemini</th>\n",
       "      <th>average-positive-score-gemini</th>\n",
       "      <th>average-negative-score-gemini</th>\n",
       "      <th>prediction-label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>591.489990</td>\n",
       "      <td>593.099976</td>\n",
       "      <td>584.549988</td>\n",
       "      <td>589.340027</td>\n",
       "      <td>589.340027</td>\n",
       "      <td>9254890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.882399</td>\n",
       "      <td>7.500</td>\n",
       "      <td>3.625</td>\n",
       "      <td>3.250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2024-11-09</td>\n",
       "      <td>591.489990</td>\n",
       "      <td>593.099976</td>\n",
       "      <td>584.549988</td>\n",
       "      <td>589.340027</td>\n",
       "      <td>589.340027</td>\n",
       "      <td>9254890</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.976398</td>\n",
       "      <td>7.250</td>\n",
       "      <td>3.125</td>\n",
       "      <td>1.750</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2024-11-11</td>\n",
       "      <td>586.760010</td>\n",
       "      <td>587.000000</td>\n",
       "      <td>576.510071</td>\n",
       "      <td>583.169983</td>\n",
       "      <td>583.169983</td>\n",
       "      <td>10046291</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.954252</td>\n",
       "      <td>7.375</td>\n",
       "      <td>3.750</td>\n",
       "      <td>2.750</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2024-11-12</td>\n",
       "      <td>587.544983</td>\n",
       "      <td>599.659973</td>\n",
       "      <td>580.440002</td>\n",
       "      <td>584.820007</td>\n",
       "      <td>584.820007</td>\n",
       "      <td>15694632</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.995730</td>\n",
       "      <td>7.625</td>\n",
       "      <td>3.875</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2024-11-13</td>\n",
       "      <td>582.559998</td>\n",
       "      <td>585.640015</td>\n",
       "      <td>575.179993</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>10038132</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.978111</td>\n",
       "      <td>7.875</td>\n",
       "      <td>3.750</td>\n",
       "      <td>2.875</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2024-11-14</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>580.760010</td>\n",
       "      <td>573.010010</td>\n",
       "      <td>577.159973</td>\n",
       "      <td>577.159973</td>\n",
       "      <td>10556017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.977997</td>\n",
       "      <td>8.000</td>\n",
       "      <td>4.375</td>\n",
       "      <td>2.750</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2024-11-19</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>559.090027</td>\n",
       "      <td>550.600098</td>\n",
       "      <td>559.025696</td>\n",
       "      <td>559.025696</td>\n",
       "      <td>6085542</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.991861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2024-11-21</td>\n",
       "      <td>569.359985</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>549.049988</td>\n",
       "      <td>563.090027</td>\n",
       "      <td>563.090027</td>\n",
       "      <td>10869427</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.991853</td>\n",
       "      <td>4.500</td>\n",
       "      <td>5.375</td>\n",
       "      <td>4.125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>2024-11-22</td>\n",
       "      <td>563.827271</td>\n",
       "      <td>563.827271</td>\n",
       "      <td>554.590027</td>\n",
       "      <td>559.140015</td>\n",
       "      <td>559.140015</td>\n",
       "      <td>9044809</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.924357</td>\n",
       "      <td>4.000</td>\n",
       "      <td>6.250</td>\n",
       "      <td>2.625</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>2024-11-25</td>\n",
       "      <td>562.979980</td>\n",
       "      <td>572.591492</td>\n",
       "      <td>556.390015</td>\n",
       "      <td>565.109985</td>\n",
       "      <td>565.109985</td>\n",
       "      <td>13460330</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.871256</td>\n",
       "      <td>5.500</td>\n",
       "      <td>5.375</td>\n",
       "      <td>4.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date        Open        High         Low       Close   Adj Close  \\\n",
       "12   2024-11-08  591.489990  593.099976  584.549988  589.340027  589.340027   \n",
       "24   2024-11-09  591.489990  593.099976  584.549988  589.340027  589.340027   \n",
       "36   2024-11-11  586.760010  587.000000  576.510071  583.169983  583.169983   \n",
       "49   2024-11-12  587.544983  599.659973  580.440002  584.820007  584.820007   \n",
       "62   2024-11-13  582.559998  585.640015  575.179993  580.000000  580.000000   \n",
       "75   2024-11-14  577.000000  580.760010  573.010010  577.159973  577.159973   \n",
       "88   2024-11-19  552.000000  559.090027  550.600098  559.025696  559.025696   \n",
       "99   2024-11-21  569.359985  570.000000  549.049988  563.090027  563.090027   \n",
       "189  2024-11-22  563.827271  563.827271  554.590027  559.140015  559.140015   \n",
       "283  2024-11-25  562.979980  572.591492  556.390015  565.109985  565.109985   \n",
       "\n",
       "       Volume  neutral-count-finbert  positive-count-finbert  \\\n",
       "12    9254890                      1                       1   \n",
       "24    9254890                      0                       0   \n",
       "36   10046291                      2                       0   \n",
       "49   15694632                      1                       0   \n",
       "62   10038132                      1                       0   \n",
       "75   10556017                      1                       0   \n",
       "88    6085542                      2                       0   \n",
       "99   10869427                      2                       0   \n",
       "189   9044809                      3                       0   \n",
       "283  13460330                      4                       2   \n",
       "\n",
       "     negative-count-finbert  average-confidence-finbert  \\\n",
       "12                        6                    0.882399   \n",
       "24                        8                    0.976398   \n",
       "36                        6                    0.954252   \n",
       "49                        7                    0.995730   \n",
       "62                        7                    0.978111   \n",
       "75                        7                    0.977997   \n",
       "88                        6                    0.991861   \n",
       "99                        6                    0.991853   \n",
       "189                       5                    0.924357   \n",
       "283                       2                    0.871256   \n",
       "\n",
       "     average-neutral-score-gemini  average-positive-score-gemini  \\\n",
       "12                          7.500                          3.625   \n",
       "24                          7.250                          3.125   \n",
       "36                          7.375                          3.750   \n",
       "49                          7.625                          3.875   \n",
       "62                          7.875                          3.750   \n",
       "75                          8.000                          4.375   \n",
       "88                            NaN                            NaN   \n",
       "99                          4.500                          5.375   \n",
       "189                         4.000                          6.250   \n",
       "283                         5.500                          5.375   \n",
       "\n",
       "     average-negative-score-gemini  prediction-label  \n",
       "12                           3.250               0.0  \n",
       "24                           1.750               0.0  \n",
       "36                           2.750               0.0  \n",
       "49                           1.250               0.0  \n",
       "62                           2.875               0.0  \n",
       "75                           2.750               1.0  \n",
       "88                             NaN               1.0  \n",
       "99                           4.125               0.0  \n",
       "189                          2.625               0.0  \n",
       "283                          4.000               1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'stock_data.csv'\n",
    "df = pd.read_csv(filename, header=0)\n",
    "df = df[~df['prediction-label'].isna()]\n",
    "meta_df = df[df['ticker']== 'META']\n",
    "meta_df = meta_df.drop(columns = ['ticker', 'number-employees', 'date_object' ])\n",
    "y = meta_df['prediction-label']\n",
    "X = meta_df.drop(columns = ['prediction-label', 'Date'])\n",
    "meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c761e15c-48e5-4b90-a98e-1c531e9cf6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume',\n",
       "       'neutral-count-finbert', 'positive-count-finbert',\n",
       "       'negative-count-finbert', 'average-confidence-finbert',\n",
       "       'average-neutral-score-gemini', 'average-positive-score-gemini',\n",
       "       'average-negative-score-gemini', 'prediction-label', 'ticker',\n",
       "       'number-employees', 'date_object'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'stock_data.csv'\n",
    "df = pd.read_csv(filename, header=0)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "01aef231-b6eb-4b6e-8c89-1c1a09e624c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'date_object', 'ticker' ]).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fac6cd3c-729f-45f5-b866-442aa0d44a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neutral-count-finbert</th>\n",
       "      <th>positive-count-finbert</th>\n",
       "      <th>negative-count-finbert</th>\n",
       "      <th>average-confidence-finbert</th>\n",
       "      <th>average-neutral-score-gemini</th>\n",
       "      <th>average-positive-score-gemini</th>\n",
       "      <th>average-negative-score-gemini</th>\n",
       "      <th>prediction-label</th>\n",
       "      <th>number-employees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.995374</td>\n",
       "      <td>6.875</td>\n",
       "      <td>4.375</td>\n",
       "      <td>3.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.893756</td>\n",
       "      <td>6.875</td>\n",
       "      <td>5.375</td>\n",
       "      <td>3.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.912988</td>\n",
       "      <td>7.125</td>\n",
       "      <td>5.250</td>\n",
       "      <td>2.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.926920</td>\n",
       "      <td>6.500</td>\n",
       "      <td>5.750</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.982125</td>\n",
       "      <td>8.250</td>\n",
       "      <td>4.125</td>\n",
       "      <td>1.750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.970963</td>\n",
       "      <td>3.375</td>\n",
       "      <td>6.375</td>\n",
       "      <td>3.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.992383</td>\n",
       "      <td>4.250</td>\n",
       "      <td>6.500</td>\n",
       "      <td>3.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998487</td>\n",
       "      <td>4.625</td>\n",
       "      <td>5.250</td>\n",
       "      <td>2.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>82700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.899729</td>\n",
       "      <td>5.250</td>\n",
       "      <td>4.375</td>\n",
       "      <td>5.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38962.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.955005</td>\n",
       "      <td>5.250</td>\n",
       "      <td>6.875</td>\n",
       "      <td>2.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76478.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     neutral-count-finbert  positive-count-finbert  negative-count-finbert  \\\n",
       "0                        3                       1                       4   \n",
       "1                        2                       2                       4   \n",
       "2                        5                       1                       2   \n",
       "3                        3                       3                       2   \n",
       "4                        1                       1                       6   \n",
       "..                     ...                     ...                     ...   \n",
       "321                      5                       2                       1   \n",
       "322                      3                       0                       5   \n",
       "323                      5                       1                       2   \n",
       "324                      0                       0                       8   \n",
       "325                      2                       1                       5   \n",
       "\n",
       "     average-confidence-finbert  average-neutral-score-gemini  \\\n",
       "0                      0.995374                         6.875   \n",
       "1                      0.893756                         6.875   \n",
       "2                      0.912988                         7.125   \n",
       "3                      0.926920                         6.500   \n",
       "4                      0.982125                         8.250   \n",
       "..                          ...                           ...   \n",
       "321                    0.970963                         3.375   \n",
       "322                    0.992383                         4.250   \n",
       "323                    0.998487                         4.625   \n",
       "324                    0.899729                         5.250   \n",
       "325                    0.955005                         5.250   \n",
       "\n",
       "     average-positive-score-gemini  average-negative-score-gemini  \\\n",
       "0                            4.375                          3.500   \n",
       "1                            5.375                          3.500   \n",
       "2                            5.250                          2.375   \n",
       "3                            5.750                          2.500   \n",
       "4                            4.125                          1.750   \n",
       "..                             ...                            ...   \n",
       "321                          6.375                          3.125   \n",
       "322                          6.500                          3.250   \n",
       "323                          5.250                          2.750   \n",
       "324                          4.375                          5.500   \n",
       "325                          6.875                          2.875   \n",
       "\n",
       "     prediction-label  number-employees  \n",
       "0                 1.0          140473.0  \n",
       "1                 0.0          164000.0  \n",
       "2                 0.0            6500.0  \n",
       "3                 0.0           88000.0  \n",
       "4                 0.0          101200.0  \n",
       "..                ...               ...  \n",
       "321               0.0          106500.0  \n",
       "322               0.0           34000.0  \n",
       "323               1.0           82700.0  \n",
       "324               0.0           38962.0  \n",
       "325               0.0           76478.0  \n",
       "\n",
       "[312 rows x 9 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "#incorporate financial data into this model by adding other columns\n",
    "#include tickers?\n",
    "#add sectors instead of tickers - yahoo finance might have sector \n",
    "#try prediction-label based on previous day/next day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a37f996-1505-4f16-833d-32c24fd4ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['prediction-label']\n",
    "X = df.drop(columns = ['prediction-label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5cdfd19d-9bf4-4563-9f13-60e2a3a56f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ce8d83cd-8ac5-4ee0-b8c9-2c73ff6704ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Prediction Probabilities: \n",
      " Class: 0  Class: 1\n",
      " 0.400377  0.599623\n",
      " 0.611841  0.388159\n",
      " 0.371825  0.628175\n",
      " 0.518613  0.481387\n",
      " 0.298773  0.701227\n",
      "Log loss: 0.6517689261512244\n",
      "Class labels: [1. 0. 1. 0. 1.]\n",
      "Accuracy: 0.6893203883495146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "# 1. Create the LogisticRegression model object below and assign to variable 'model'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "model = LogisticRegression()\n",
    "\n",
    "# 2. Fit the model to the training data below\n",
    "\n",
    "# YOUR CODE HERE\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Make predictions on the test data using the predict_proba() method and assign the \n",
    "# result to the variable 'probability_predictions' below\n",
    "\n",
    "# YOUR CODE HERE\n",
    "probability_predictions = model.predict_proba(X_test)\n",
    "\n",
    "# print the first 5 probability class predictions\n",
    "df_print = pd.DataFrame(probability_predictions, columns = ['Class: 0', 'Class: 1'])\n",
    "print('Class Prediction Probabilities: \\n' + df_print[0:5].to_string(index=False))\n",
    "\n",
    "# 4. Compute the log loss on 'probability_predictions' and save the result to the variable\n",
    "# 'l_loss' below\n",
    "\n",
    "# YOUR CODE HERE\n",
    "l_loss = log_loss(y_test, probability_predictions)\n",
    "print('Log loss: ' + str(l_loss))\n",
    "\n",
    "\n",
    "# 5. Make predictions on the test data using the predict() method and assign the result \n",
    "# to the variable 'class_label_predictions' below\n",
    "\n",
    "# YOUR CODE HERE\n",
    "class_label_predictions = model.predict(X_test)\n",
    "\n",
    "# print the first 5 class label predictions \n",
    "print('Class labels: ' + str(class_label_predictions[0:5]))\n",
    "\n",
    "# 6.Compute the accuracy score on 'class_label_predictions' and save the result \n",
    "# to the variable 'acc_score' below\n",
    "\n",
    "# YOUR CODE HERE\n",
    "acc_score = accuracy_score(y_test, class_label_predictions)\n",
    "print('Accuracy: ' + str(acc_score))\n",
    "\n",
    "#readability add descriptive labels in output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9d176e64-4188-4168-a784-f301d7fe0f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\user\\anaconda3\\lib\\site-packages\\matlabengine-24.2-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\user\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\user\\anaconda3\\lib\\site-packages\\matlabengine-24.2-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "97c9e219-8101-461b-88a2-4cf89952cc63",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "all elements of target should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[200], line 94\u001b[0m\n\u001b[0;32m     91\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     93\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs) \u001b[38;5;66;03m# Get model predictions for the current batch\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)  \u001b[38;5;66;03m# Calculate the loss\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[0;32m     97\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Clear previous gradients\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:697\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 697\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(\n\u001b[0;32m    698\u001b[0m         \u001b[38;5;28minput\u001b[39m, target, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction\n\u001b[0;32m    699\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:3554\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3551\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m   3552\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[1;32m-> 3554\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(\u001b[38;5;28minput\u001b[39m, target, weight, reduction_enum)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: all elements of target should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Define the LSTM model class\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # Define a fully connected (linear) layer for output\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        #sigmoid function because this is classification\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # LSTM outputs\n",
    "        lstm_out, (hn, cn) = self.lstm(x)  # hn is the hidden state from the last LSTM layer\n",
    "        \n",
    "        # We take the output from the last time step\n",
    "        out = self.fc(hn[-1])\n",
    "        out = self.sigmoid(out)\n",
    "          \n",
    "        return out\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 8  # Number of features in each time step (can vary based on your dataset)\n",
    "hidden_size = 50  # Number of LSTM units in each layer\n",
    "output_size = 1  # For regression, change this for classification (e.g., number of classes)\n",
    "num_layers = 1  # Number of LSTM layers\n",
    "batch_size = 32\n",
    "seq_length = 20  # Length of each input sequence\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Generate some synthetic data for demonstration (e.g., time-series regression)\n",
    "# Let's generate a random sequence with 1000 samples of length 20\n",
    "df = pd.read_csv('stock_data.csv')\n",
    "df = df[df[\"ticker\"]==\"AAPL\"]\n",
    "df = df.select_dtypes(include=[np.number]).dropna()\n",
    "\n",
    "# Convert data into sequences for LSTM input\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data.iloc[i:i+seq_length, 0].values  # Accessing the first column (numerical data)\n",
    "        y = data.iloc[i+seq_length, 0]  # The value at the next timestep\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Set sequence length\n",
    "SEQ_LENGTH = 8\n",
    "\n",
    "# Create sequences\n",
    "X, y = create_sequences(df, SEQ_LENGTH)\n",
    "\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# Split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model = LSTMModel(input_size, hidden_size, output_size, num_layers)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Using binary cross entropy loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    outputs = model(inputs) # Get model predictions for the current batch\n",
    "    loss = criterion(outputs, targets)  # Calculate the loss\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()  # Clear previous gradients\n",
    "    loss.backward()  # Compute gradients\n",
    "    optimizer.step()  # Update model parameters\n",
    "    \n",
    "    # Print loss every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0 and batch_idx == len(train_loader) - 1:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "        \n",
    "          \n",
    "# After training, you can make predictions like this:\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    test_input = torch.randn(1, seq_length, input_size)  # A single sample\n",
    "    prediction = model(test_input)\n",
    "    predicted_class = (prediction >= 0.5).float()  # Classify as 1 if probability >= 0.5, else 0\n",
    "    print(\"Prediction:\", predicted_class.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "58bf81a3-1593-4b13-bdef-eb5522f12c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>neutral-count-finbert</th>\n",
       "      <th>positive-count-finbert</th>\n",
       "      <th>negative-count-finbert</th>\n",
       "      <th>average-confidence-finbert</th>\n",
       "      <th>average-neutral-score-gemini</th>\n",
       "      <th>average-positive-score-gemini</th>\n",
       "      <th>average-negative-score-gemini</th>\n",
       "      <th>prediction-label</th>\n",
       "      <th>number-employees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>227.139999</td>\n",
       "      <td>228.660004</td>\n",
       "      <td>226.408401</td>\n",
       "      <td>226.960007</td>\n",
       "      <td>226.960007</td>\n",
       "      <td>37608324</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.893756</td>\n",
       "      <td>6.875</td>\n",
       "      <td>5.375</td>\n",
       "      <td>3.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>227.139999</td>\n",
       "      <td>228.660004</td>\n",
       "      <td>226.408401</td>\n",
       "      <td>226.960007</td>\n",
       "      <td>226.960007</td>\n",
       "      <td>37608324</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.974607</td>\n",
       "      <td>6.250</td>\n",
       "      <td>2.375</td>\n",
       "      <td>1.750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>225.054993</td>\n",
       "      <td>225.699997</td>\n",
       "      <td>221.500000</td>\n",
       "      <td>224.229996</td>\n",
       "      <td>224.229996</td>\n",
       "      <td>41415717</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.945336</td>\n",
       "      <td>6.500</td>\n",
       "      <td>6.500</td>\n",
       "      <td>1.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>224.630005</td>\n",
       "      <td>225.589996</td>\n",
       "      <td>223.354996</td>\n",
       "      <td>224.229996</td>\n",
       "      <td>224.229996</td>\n",
       "      <td>34988619</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.993764</td>\n",
       "      <td>7.500</td>\n",
       "      <td>4.750</td>\n",
       "      <td>2.750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>224.009995</td>\n",
       "      <td>226.649994</td>\n",
       "      <td>222.759995</td>\n",
       "      <td>225.119995</td>\n",
       "      <td>225.119995</td>\n",
       "      <td>47686733</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.905029</td>\n",
       "      <td>6.750</td>\n",
       "      <td>6.125</td>\n",
       "      <td>2.125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>164000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>225.070007</td>\n",
       "      <td>228.869995</td>\n",
       "      <td>225.050003</td>\n",
       "      <td>228.220001</td>\n",
       "      <td>228.220001</td>\n",
       "      <td>43401721</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.939148</td>\n",
       "      <td>6.000</td>\n",
       "      <td>5.875</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>164000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>225.919998</td>\n",
       "      <td>226.919998</td>\n",
       "      <td>224.270004</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>46862701</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.991967</td>\n",
       "      <td>6.125</td>\n",
       "      <td>2.750</td>\n",
       "      <td>5.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>228.789993</td>\n",
       "      <td>230.149994</td>\n",
       "      <td>225.710297</td>\n",
       "      <td>228.520004</td>\n",
       "      <td>228.520004</td>\n",
       "      <td>40355157</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.932328</td>\n",
       "      <td>5.000</td>\n",
       "      <td>5.375</td>\n",
       "      <td>4.625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>228.059998</td>\n",
       "      <td>230.719894</td>\n",
       "      <td>228.059998</td>\n",
       "      <td>229.869995</td>\n",
       "      <td>229.869995</td>\n",
       "      <td>36963884</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.994476</td>\n",
       "      <td>3.875</td>\n",
       "      <td>7.125</td>\n",
       "      <td>2.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>164000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>231.460007</td>\n",
       "      <td>233.244995</td>\n",
       "      <td>229.740005</td>\n",
       "      <td>232.869995</td>\n",
       "      <td>232.869995</td>\n",
       "      <td>86333323</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.946358</td>\n",
       "      <td>5.250</td>\n",
       "      <td>4.500</td>\n",
       "      <td>4.125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>164000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Open        High         Low       Close   Adj Close    Volume  \\\n",
       "1    227.139999  228.660004  226.408401  226.960007  226.960007  37608324   \n",
       "13   227.139999  228.660004  226.408401  226.960007  226.960007  37608324   \n",
       "25   225.054993  225.699997  221.500000  224.229996  224.229996  41415717   \n",
       "38   224.630005  225.589996  223.354996  224.229996  224.229996  34988619   \n",
       "51   224.009995  226.649994  222.759995  225.119995  225.119995  47686733   \n",
       "64   225.070007  228.869995  225.050003  228.220001  228.220001  43401721   \n",
       "77   225.919998  226.919998  224.270004  225.000000  225.000000  46862701   \n",
       "101  228.789993  230.149994  225.710297  228.520004  228.520004  40355157   \n",
       "191  228.059998  230.719894  228.059998  229.869995  229.869995  36963884   \n",
       "284  231.460007  233.244995  229.740005  232.869995  232.869995  86333323   \n",
       "\n",
       "     neutral-count-finbert  positive-count-finbert  negative-count-finbert  \\\n",
       "1                        2                       2                       4   \n",
       "13                       1                       0                       7   \n",
       "25                       3                       0                       5   \n",
       "38                       2                       1                       5   \n",
       "51                       4                       0                       4   \n",
       "64                       3                       0                       5   \n",
       "77                       2                       1                       5   \n",
       "101                      4                       1                       3   \n",
       "191                      5                       0                       3   \n",
       "284                      2                       1                       5   \n",
       "\n",
       "     average-confidence-finbert  average-neutral-score-gemini  \\\n",
       "1                      0.893756                         6.875   \n",
       "13                     0.974607                         6.250   \n",
       "25                     0.945336                         6.500   \n",
       "38                     0.993764                         7.500   \n",
       "51                     0.905029                         6.750   \n",
       "64                     0.939148                         6.000   \n",
       "77                     0.991967                         6.125   \n",
       "101                    0.932328                         5.000   \n",
       "191                    0.994476                         3.875   \n",
       "284                    0.946358                         5.250   \n",
       "\n",
       "     average-positive-score-gemini  average-negative-score-gemini  \\\n",
       "1                            5.375                          3.500   \n",
       "13                           2.375                          1.750   \n",
       "25                           6.500                          1.375   \n",
       "38                           4.750                          2.750   \n",
       "51                           6.125                          2.125   \n",
       "64                           5.875                          1.750   \n",
       "77                           2.750                          5.250   \n",
       "101                          5.375                          4.625   \n",
       "191                          7.125                          2.875   \n",
       "284                          4.500                          4.125   \n",
       "\n",
       "     prediction-label  number-employees  \n",
       "1                 0.0          164000.0  \n",
       "13                0.0          164000.0  \n",
       "25                0.0          164000.0  \n",
       "38                0.0          164000.0  \n",
       "51                1.0          164000.0  \n",
       "64                1.0          164000.0  \n",
       "77                0.0          164000.0  \n",
       "101               0.0          164000.0  \n",
       "191               1.0          164000.0  \n",
       "284               1.0          164000.0  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64399b9a-32a3-456f-8711-f429845532f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
